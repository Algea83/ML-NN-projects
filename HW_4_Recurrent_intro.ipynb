{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"HW_4_Введение в рекуррентные НС","provenance":[{"file_id":"1y2vX9lOI1KaMyOJbGegKs5QwVrkBRso5","timestamp":1653909934324},{"file_id":"https://github.com/waytobehigh/nlp_course/blob/master/week05_structured/rnn_tagger.ipynb","timestamp":1617022812789}],"collapsed_sections":["CEBlZFZOFhYc","0FOmIgtLfeSf","dptTNTiofhYv","AouayJ2ylDOl","pWlhQM_Krtbw","NI_RbGdHwCDs","JZYJnDLawGdh"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Реализация частеречной разметки (POS tagging) посредством нейронных сетей, основное задание"],"metadata":{"id":"CEBlZFZOFhYc"}},{"cell_type":"markdown","source":["С точки зрения глубокого обучения, частеречная разметка - задача предсказания последовательности вывода выровненная с последовательностью ввода. \n","<img src=https://i.stack.imgur.com/6pdIT.png width=320>\n","\n","Существуют несколько проблем, описываемых этой задачей:\n","- Частеречная разметка - сопутствующая задача для большого числа проблем обработки естественного языка;\n","- Извлечение именованных сущностей - для чатботов и поисковых роботов;\n","- Предсказание структур белка - для биоинформатики."],"metadata":{"id":"v9m364EuFoMT"}},{"cell_type":"markdown","source":["## Загрузка данных"],"metadata":{"id":"0FOmIgtLfeSf"}},{"cell_type":"code","metadata":{"scrolled":true,"id":"yxFUBtb88aHq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654094459936,"user_tz":-180,"elapsed":10043,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}},"outputId":"66e28df0-f473-4d5a-ae0c-f81ebe8e5d7e"},"source":["# Импорт необходимых библиотек\n","import nltk                   # Библиотека для работы с естественным языком\n","import sys                    # Библиотека для доступа к системным параметрам и функциям\n","import numpy as np            # Библиотека для реализации функций линейной алгебры\n","\n","# Загрузка корпуса Brown - коллекции документов на английском, созданной в 1961 году\n","# Особенность этого корпуса в том, что документы там уже токенизированы и размечены\n","nltk.download('brown')\n","# Загрузка альтернативного набора меток, обозначающих части речи\n","nltk.download('universal_tagset')\n","\n","# Запись корпуса Brown в переменную, вместе с альтернативной частеречной разметкой\n","data = nltk.corpus.brown.tagged_sents(tagset='universal')\n","# Ограничение списка разметки\n","all_tags = ['#EOS#','#UNK#','ADV', 'NOUN', 'ADP', 'PRON', 'DET', '.', 'PRT', 'VERB', 'X', 'NUM', 'CONJ', 'ADJ']\n","\n","# Приведение слов в корпусе к нижнему регистру, определение каждого предложения в свой список\n","data = np.array([ [(word.lower(),tag) for word, tag in sentence] for sentence in data ])"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n","[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n","[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]}]},{"cell_type":"code","source":["# Визуальное исследование элемента набора данных data\n","data[10]"],"metadata":{"id":"Z0DgH6wKWWHi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654094459937,"user_tz":-180,"elapsed":19,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}},"outputId":"79b2f2fc-f7b8-42f3-ed62-cafb33f85536"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('it', 'PRON'),\n"," ('urged', 'VERB'),\n"," ('that', 'ADP'),\n"," ('the', 'DET'),\n"," ('city', 'NOUN'),\n"," ('``', '.'),\n"," ('take', 'VERB'),\n"," ('steps', 'NOUN'),\n"," ('to', 'PRT'),\n"," ('remedy', 'VERB'),\n"," (\"''\", '.'),\n"," ('this', 'DET'),\n"," ('problem', 'NOUN'),\n"," ('.', '.')]"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"Bq_OXuD38aHs","executionInfo":{"status":"ok","timestamp":1654094459938,"user_tz":-180,"elapsed":18,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}}},"source":["# Импорт библиотеки для разделения данных на обучающие и проверочные\n","from sklearn.model_selection import train_test_split\n","# Импорт необходимых библиотек для отображения элементов набора данных\n","from IPython.display import HTML, display"],"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Разделение данных на обучающие (75%) и проверочные (25%)\n","train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)"],"metadata":{"id":"e-0U2almYsd7","executionInfo":{"status":"ok","timestamp":1654094459939,"user_tz":-180,"elapsed":18,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"sAlXrDmU8aHs","executionInfo":{"status":"ok","timestamp":1654094459940,"user_tz":-180,"elapsed":19,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}}},"source":["def draw(sentence):\n","  \"\"\"Функция для удобочитаемого отображения загруженного частеречно размеченного текста\"\"\"\n","  words, tags = zip(*sentence)\n","  display(HTML('<table><tr>{tags}</tr>{words}<tr></table>'.format(\n","                words = '<td>{}</td>'.format('</td><td>'.join(words)),\n","                tags = '<td>{}</td>'.format('</td><td>'.join(tags)))))"],"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Визуальное исследование нового отображения\n","draw(data[11])\n","draw(data[7])\n","draw(data[10])"],"metadata":{"id":"kotxn4P7Ykle","colab":{"base_uri":"https://localhost:8080/","height":152},"executionInfo":{"status":"ok","timestamp":1654094459941,"user_tz":-180,"elapsed":19,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}},"outputId":"5b80cb89-bab5-430d-97d2-b54836b866a0"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table><tr><td>NOUN</td><td>ADP</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>VERB</td><td>ADV</td><td>VERB</td><td>ADP</td><td>DET</td><td>ADJ</td><td>NOUN</td><td>.</td></tr><td>implementation</td><td>of</td><td>georgia's</td><td>automobile</td><td>title</td><td>law</td><td>was</td><td>also</td><td>recommended</td><td>by</td><td>the</td><td>outgoing</td><td>jury</td><td>.</td><tr></table>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table><tr><td>NOUN</td><td>VERB</td></tr><td>merger</td><td>proposed</td><tr></table>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table><tr><td>PRON</td><td>VERB</td><td>ADP</td><td>DET</td><td>NOUN</td><td>.</td><td>VERB</td><td>NOUN</td><td>PRT</td><td>VERB</td><td>.</td><td>DET</td><td>NOUN</td><td>.</td></tr><td>it</td><td>urged</td><td>that</td><td>the</td><td>city</td><td>``</td><td>take</td><td>steps</td><td>to</td><td>remedy</td><td>''</td><td>this</td><td>problem</td><td>.</td><tr></table>"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Построение словарей"],"metadata":{"id":"dptTNTiofhYv"}},{"cell_type":"markdown","source":["Для приведения коллекции документов в вид, пригодный для отправки в нейронную сеть необходимо отобразить текстовые токены в целочисленное пространство. В данном случае модель бует оперировать на уровне слов, обрабатывая одно слово за один рекуррентный шаг. Соответственно, это приведет к словарю значительного размера.\n","\n","Учитывая, что словарь данного размера будет являться входящими данными для нашей нейронной сети, используя слой Embedding, можно довольно просто превратить эти данные в плотные векторы."],"metadata":{"id":"Vyj1q8Mpfk8j"}},{"cell_type":"code","metadata":{"collapsed":true,"id":"ZXK_k-mo8aHt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654094461003,"user_tz":-180,"elapsed":1072,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}},"outputId":"5e58ae1e-5698-4d94-fcf5-66736fcbcaf3"},"source":["# Импортируем счетчик\n","from collections import Counter\n","# Инициализируем счет слов в наборе данных\n","word_counts = Counter()\n","\n","# Посчитаем, сколько каждое слово встречается в наборе данных\n","# Результат - объект Counter, в котором содержится словар вида {слово: количество раз в наборе данных}\n","for sentence in data:\n","    words, tags = zip(*sentence)\n","    word_counts.update(words)\n","\n","# Создаем список, содержащий элемент, соответствующие словам, не содержащимся в словаре (#UNK#), а также padding-элемент (#EOS#)\n","# Оставляем в этом списке только 10000 самых часто попадающихся в наборе данных слов\n","all_words = ['#EOS#','#UNK#'] + list(list(zip(*word_counts.most_common(10000)))[0])\n","\n","# Посчитаем, какое количество слов в наборе данных покрывается словарем, созданным выше\n","print(\"Покрытие = %.5f\" % (float(sum(word_counts[w] for w in all_words)) / sum(word_counts.values())))"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Покрытие = 0.92876\n"]}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"T0hee8L88aHt","executionInfo":{"status":"ok","timestamp":1654094461004,"user_tz":-180,"elapsed":7,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}}},"source":["# Импортируем модуль для создания словарей. От классических словарей отличается тем, что в нем невозможно возникновение KeyError\n","# Вместо этого на место несуществующего ключа вставляется ключ по умолчанию\n","from collections import defaultdict\n","# Создаем ивертированный индекс для словаря из прошлого шага\n","word_to_id = defaultdict(lambda:1, { word: i for i, word in enumerate(all_words) })\n","# И такой же индекс для списка меток\n","tag_to_id = { tag: i for i, tag in enumerate(all_tags)}"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RCmGbwpP8aHu"},"source":["Преобразуем токены и метки в матрицу фиксированного размера"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"X7kx6jWn8aHu","executionInfo":{"status":"ok","timestamp":1654094461005,"user_tz":-180,"elapsed":7,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}}},"source":["def to_matrix(lines, token_to_id, max_len=None, pad=0, dtype='int32', time_major=False):\n","    \"\"\"Ковертирует список токенов в матрицу фиксированной размерности, подходящую для нейронной сети.\"\"\"\n","    \n","    # Из поступающих данных выбирается строка максимальной длины или же длины, поданной как параметр\n","    max_len = max_len or max(map(len,lines))\n","    # Создается пустая матрица размерности: количество строк*маскимальная длина\n","    matrix = np.empty([len(lines), max_len],dtype)\n","    # Матрица заполняется значениями, подаными как параметр функции\n","    matrix.fill(pad)\n","\n","    # На месте предыдущих значений записываются индексы, соответствующими словам в строках\n","    for i in range(len(lines)):\n","        line_ix = list(map(token_to_id.__getitem__,lines[i]))[:max_len]\n","        matrix[i,:len(line_ix)] = line_ix\n","\n","    return matrix.T if time_major else matrix\n","\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"BCaE-i5u8aHu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654094461005,"user_tz":-180,"elapsed":6,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}},"outputId":"aacc3451-a319-4203-d3f7-eb8a57cb289d"},"source":["# Проверим, что у нас получилось на трёх последних элементах набора данных (токены и метки отдельно)\n","batch_words, batch_tags = zip(*[zip(*sentence) for sentence in data[-3:]])\n","\n","print(\"Матрица индексов токенов:\")\n","print(to_matrix(batch_words, word_to_id))\n","print(\"Матрица индексов меток:\")\n","print(to_matrix(batch_tags, tag_to_id))"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Матрица индексов токенов:\n","[[   2 3057    5    2 2238 1334 4238 2454    3    6   19   26 1070   69\n","     8 2088    6    3    1    3  266   65  342    2    1    3    2  315\n","     1    9   87  216 3322   69 1558    4    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0]\n"," [  45   12    8  511 8419    6   60 3246   39    2    1    1    3    2\n","   845    1    3    1    3   10 9910    2    1 3470    9   43    1    1\n","     3    6    2 1046  385   73 4562    3    9    2    1    1 3250    3\n","    12   10    2  861 5240   12    8 8936  121    1    4]\n"," [  33   64   26   12  445    7 7346    9    8 3337    3    1 2811    3\n","     2  463  572    2    1    1 1649   12    1    4    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0]]\n","Матрица индексов меток:\n","[[ 6  3  4  6  3  3  9  9  7 12  4  5  9  4  6  3 12  7  9  7  9  8  4  6\n","   3  7  6 13  3  4  6  3  9  4  3  7  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0]\n"," [ 5  9  6  9  3 12  6  3  7  6 13  3  7  6 13  3  7 13  7  5  9  6  3  3\n","   4  6 13  3  7 12  6  3  6 13  3  7  4  6  3  9  3  7  9  4  6 13  3  9\n","   6  3  2 13  7]\n"," [ 4  6  5  9 13  4  3  4  6 13  7 13  3  7  6  3  4  6 13  3  3  9  9  7\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0]]\n"]}]},{"cell_type":"markdown","source":["## Создадим модель"],"metadata":{"id":"AouayJ2ylDOl"}},{"cell_type":"markdown","source":["По умолчанию рекуррентный слой keras применяется ко всей последовательности входящих данных и выдает либо последовательность скрытых состояний, либо последнее скрытое состояние (в зависимости от настройки слоя). Сам рекуррентный процесс происходит автономно, \"под капотом\".\n","\n","Завершающим слоем нашей модели должен быть полносвязный слой, применяемый на каждом временном шаге независимо от прочих шагов. Если использовать полносвязный слой Dense как есть, то он применится ко всем временным шагам в совокупности. Необходимо использовать слой TimeDistributed с целью корректной реализации как по партии, так и по времени."],"metadata":{"id":"dYsMBZEmlFh_"}},{"cell_type":"code","metadata":{"id":"OQeb8d5j8aHv","executionInfo":{"status":"ok","timestamp":1654094468214,"user_tz":-180,"elapsed":7214,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}}},"source":["# Импортируем библиотеку keras\n","import keras\n","# Импортируем слои\n","import keras.layers as L\n","\n","# Инициализируем модель, в которой все слои будут располагаться последовательно\n","model = keras.models.Sequential()\n","# Слой для входящих данных\n","model.add(L.InputLayer([None], dtype='int32'))\n","# Слой для превращения целочисленных входящих матриц в плотный вектор\n","model.add(L.Embedding(len(all_words),50))\n","# Рекуррентный слой\n","model.add(L.SimpleRNN(64, return_sequences=True))\n","\n","#add top layer that predicts tag probabilities\n","# Слой для предсказания вероятностей той или иной метки из списка доступных меток\n","stepwise_dense = L.Dense(len(all_tags), activation='softmax')\n","# Слой для предсказания вероятностей с учетом временных шагов, добавляем в модель именно его\n","stepwise_dense = L.TimeDistributed(stepwise_dense)\n","model.add(stepwise_dense)"],"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Собираем модель\n","model.compile('adam','categorical_crossentropy')"],"metadata":{"id":"id_5yWCYrTkZ","executionInfo":{"status":"ok","timestamp":1654094468215,"user_tz":-180,"elapsed":23,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Смотрим на архитектуру модели\n","model.summary()"],"metadata":{"id":"zKmaXj6ArUqY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654094468215,"user_tz":-180,"elapsed":21,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}},"outputId":"cbf30d2e-fe25-4a19-967c-cd7b4e1a6a62"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, None, 50)          500100    \n","                                                                 \n"," simple_rnn (SimpleRNN)      (None, None, 64)          7360      \n","                                                                 \n"," time_distributed (TimeDistr  (None, None, 14)         910       \n"," ibuted)                                                         \n","                                                                 \n","=================================================================\n","Total params: 508,370\n","Trainable params: 508,370\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["## Обучение модели"],"metadata":{"id":"pWlhQM_Krtbw"}},{"cell_type":"markdown","source":["В данном случае, учитывая, что размерность матриц в каждой партии будет зависеть от максимальной длины предложения в этой партии, целесообразно использование генераторов и соответствующего метода для обучения модели."],"metadata":{"id":"sp7ZKhBrryg9"}},{"cell_type":"code","metadata":{"collapsed":true,"id":"kpeMsDi18aHw","executionInfo":{"status":"ok","timestamp":1654094468216,"user_tz":-180,"elapsed":17,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}}},"source":["# Создаем генератор для подачи входящих данных в обучение партиями\n","# Обработка данных генераторами позволяет использовать и ЦПУ для генерирования партий, и ГПУ для обучения\n","# максимальным образом используя возможности системы\n","from keras.utils.np_utils import to_categorical\n","BATCH_SIZE=32\n","\n","# Функция-генератор\n","def generate_batches(sentences,batch_size=BATCH_SIZE,max_len=None,pad=0):\n","    assert isinstance(sentences,np.ndarray),\"Make sure sentences is q numpy array\"\n","    \n","    while True:\n","        indices = np.random.permutation(np.arange(len(sentences)))\n","        for start in range(0,len(indices)-1,batch_size):\n","            batch_indices = indices[start:start+batch_size]\n","            batch_words,batch_tags = [],[]\n","            for sent in sentences[batch_indices]:\n","                words,tags = zip(*sent)\n","                batch_words.append(words)\n","                batch_tags.append(tags)\n","\n","            batch_words = to_matrix(batch_words,word_to_id,max_len,pad)\n","            batch_tags = to_matrix(batch_tags,tag_to_id,max_len,pad)\n","\n","            batch_tags_1hot = to_categorical(batch_tags,len(all_tags)).reshape(batch_tags.shape+(-1,))\n","            yield batch_words,batch_tags_1hot\n","        "],"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["Еще один необходимый элемент контроля качества обучения модели - измерение её эффективности."],"metadata":{"id":"McLF6p19slu2"}},{"cell_type":"code","metadata":{"collapsed":true,"id":"CC8woNtV8aHx","executionInfo":{"status":"ok","timestamp":1654094468217,"user_tz":-180,"elapsed":17,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}}},"source":["# Функция для расчета точности модели на данных для проверки\n","def compute_test_accuracy(model):\n","    test_words,test_tags = zip(*[zip(*sentence) for sentence in test_data])\n","    test_words,test_tags = to_matrix(test_words,word_to_id),to_matrix(test_tags,tag_to_id)\n","\n","    # Предсказание вероятностей меток\n","    predicted_tag_probabilities = model.predict(test_words,verbose=1)\n","    predicted_tags = predicted_tag_probabilities.argmax(axis=-1)\n","\n","    # Расчёт точности, исключая технические метки padding\n","    numerator = np.sum(np.logical_and((predicted_tags == test_tags),(test_words != 0)))\n","    denominator = np.sum(test_words != 0)\n","    return float(numerator)/denominator\n","\n","# В конце каждой эпохи обучения, специальный случай callback\n","class EvaluateAccuracy(keras.callbacks.Callback):\n","    def on_epoch_end(self,epoch,logs=None):\n","        sys.stdout.flush()\n","        print(\"\\nИзмеряю точность на данных для валидации...\")\n","        acc = compute_test_accuracy(self.model)\n","        print(\"\\nТочность на данных для валидации: %.5f\\n\"%acc)\n","        sys.stdout.flush()"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"5eJGEWu58aHx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654094847978,"user_tz":-180,"elapsed":379778,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}},"outputId":"3b1f2282-93a9-4c00-8958-6de730de928c"},"source":["# Обучение модели, 5 эпох\n","model.fit_generator(generate_batches(train_data), len(train_data)/BATCH_SIZE,\n","                   callbacks=[EvaluateAccuracy()], epochs=5)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]},{"output_type":"stream","name":"stdout","text":["1344/1343 [==============================] - ETA: 0s - loss: 0.2646\n","Измеряю точность на данных для валидации...\n","448/448 [==============================] - 6s 13ms/step\n","\n","Точность на данных для валидации: 0.93993\n","\n","1343/1343 [==============================] - 78s 56ms/step - loss: 0.2646\n","Epoch 2/5\n","1344/1343 [==============================] - ETA: 0s - loss: 0.0595\n","Измеряю точность на данных для валидации...\n","448/448 [==============================] - 6s 14ms/step\n","\n","Точность на данных для валидации: 0.94425\n","\n","1343/1343 [==============================] - 77s 58ms/step - loss: 0.0595\n","Epoch 3/5\n","1343/1343 [============================>.] - ETA: 0s - loss: 0.0518\n","Измеряю точность на данных для валидации...\n","448/448 [==============================] - 6s 14ms/step\n","\n","Точность на данных для валидации: 0.94679\n","\n","1343/1343 [==============================] - 77s 57ms/step - loss: 0.0518\n","Epoch 4/5\n","1344/1343 [==============================] - ETA: 0s - loss: 0.0473\n","Измеряю точность на данных для валидации...\n","448/448 [==============================] - 6s 13ms/step\n","\n","Точность на данных для валидации: 0.94664\n","\n","1343/1343 [==============================] - 75s 56ms/step - loss: 0.0473\n","Epoch 5/5\n","1344/1343 [==============================] - ETA: 0s - loss: 0.0429\n","Измеряю точность на данных для валидации...\n","448/448 [==============================] - 6s 13ms/step\n","\n","Точность на данных для валидации: 0.94524\n","\n","1343/1343 [==============================] - 72s 54ms/step - loss: 0.0429\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f13c0255250>"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["## Проверка точности модели"],"metadata":{"id":"NI_RbGdHwCDs"}},{"cell_type":"markdown","metadata":{"id":"TTN7C34V8aHy"},"source":["Измеряем окончательную точность на данных для проверки."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"tHgxnYB68aHy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654094858934,"user_tz":-180,"elapsed":10967,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}},"outputId":"ada764d9-fe3e-46fd-a608-dadc370f70ca"},"source":["acc = compute_test_accuracy(model)\n","print(\"Точность на данных для проверки: %.5f\"%acc)\n","\n","assert acc > 0.94, \"Результаты так себе\""],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["448/448 [==============================] - 6s 13ms/step\n","Точность на данных для проверки: 0.94524\n"]}]},{"cell_type":"markdown","source":["# Двунаправленные рекуррентные нейронные сети"],"metadata":{"id":"JZYJnDLawGdh"}},{"cell_type":"markdown","source":["Учитывая, что мы анализируем за один подход целое предложение, совершенно нормально для предсказания опираться не только на предыдущие данные, но и на последующие (согласно специфике естественных языков). Самый простой способ реализовать этот подход заключается в использовании двунаправленных рекуррентных нейронных сетей."],"metadata":{"id":"Oww9gmUjwP5q"}},{"cell_type":"code","metadata":{"collapsed":true,"id":"xWfCrbh-8aHy","executionInfo":{"status":"ok","timestamp":1654094859487,"user_tz":-180,"elapsed":564,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}}},"source":["# Создаем архитектуру модели, использующей двунаправленный рекуррентный слой\n","model = keras.models.Sequential()\n","\n","# Слой для входящих данных\n","model.add(L.InputLayer([None], dtype='int32'))\n","# Слой для превращения целочисленных входящих матриц в плотный вектор\n","model.add(L.Embedding(len(all_words), 50))\n","# Рекуррентный двунаправленный слой, реализующий слой long short term memory\n","model.add(L.Bidirectional(L.LSTM(64, return_sequences=True)))\n","# Слой для предсказания вероятностей той или иной метки из списка доступных меток\n","stepwise_dense = L.Dense(len(all_tags), activation='softmax')\n","# Слой для предсказания вероятностей с учетом временных шагов, добавляем в модель именно его\n","stepwise_dense = L.TimeDistributed(stepwise_dense)\n","model.add(stepwise_dense)\n"],"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Собираем модель\n","model.compile('adam','categorical_crossentropy')"],"metadata":{"id":"PHP9cU72xnih","executionInfo":{"status":"ok","timestamp":1654094859488,"user_tz":-180,"elapsed":10,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Визуализируем архитектуру модели\n","model.summary()"],"metadata":{"id":"3f-KFsDYxrSG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654094859488,"user_tz":-180,"elapsed":9,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}},"outputId":"319e3071-2836-4a4b-ee00-fbb2b0d152fa"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, None, 50)          500100    \n","                                                                 \n"," bidirectional (Bidirectiona  (None, None, 128)        58880     \n"," l)                                                              \n","                                                                 \n"," time_distributed_1 (TimeDis  (None, None, 14)         1806      \n"," tributed)                                                       \n","                                                                 \n","=================================================================\n","Total params: 560,786\n","Trainable params: 560,786\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Ort64W348aHz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654095004277,"user_tz":-180,"elapsed":144792,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}},"outputId":"4d2a1c6f-f539-4b94-94fc-7ebab2404d8e"},"source":["# Обучаем новую модель\n","model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n","                    callbacks=[EvaluateAccuracy()], epochs=5)"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]},{"output_type":"stream","name":"stdout","text":["1340/1343 [============================>.] - ETA: 0s - loss: 0.2584\n","Измеряю точность на данных для валидации...\n","448/448 [==============================] - 3s 6ms/step\n","\n","Точность на данных для валидации: 0.95536\n","\n","1343/1343 [==============================] - 24s 14ms/step - loss: 0.2578\n","Epoch 2/5\n","1339/1343 [============================>.] - ETA: 0s - loss: 0.0442\n","Измеряю точность на данных для валидации...\n","448/448 [==============================] - 3s 6ms/step\n","\n","Точность на данных для валидации: 0.96093\n","\n","1343/1343 [==============================] - 18s 14ms/step - loss: 0.0442\n","Epoch 3/5\n","1344/1343 [==============================] - ETA: 0s - loss: 0.0367\n","Измеряю точность на данных для валидации...\n","448/448 [==============================] - 3s 6ms/step\n","\n","Точность на данных для валидации: 0.96416\n","\n","1343/1343 [==============================] - 15s 11ms/step - loss: 0.0367\n","Epoch 4/5\n","1342/1343 [============================>.] - ETA: 0s - loss: 0.0318\n","Измеряю точность на данных для валидации...\n","448/448 [==============================] - 3s 6ms/step\n","\n","Точность на данных для валидации: 0.96465\n","\n","1343/1343 [==============================] - 18s 13ms/step - loss: 0.0318\n","Epoch 5/5\n","1339/1343 [============================>.] - ETA: 0s - loss: 0.0283\n","Измеряю точность на данных для валидации...\n","448/448 [==============================] - 3s 6ms/step\n","\n","Точность на данных для валидации: 0.96523\n","\n","1343/1343 [==============================] - 15s 11ms/step - loss: 0.0283\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f13424323d0>"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"iWHSkF648aHz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654095008627,"user_tz":-180,"elapsed":4356,"user":{"displayName":"Svetlana Gavrikova","userId":"16591925971947533375"}},"outputId":"fdac7600-4851-45d5-ce40-9c57c391c9d2"},"source":["# Рассчитываю точность на данных для проверки\n","acc = compute_test_accuracy(model)\n","print(\"\\nОкончательная точность на тестовых данных: %.5f\"%acc)\n","\n","assert acc > 0.96, \"Должно было быть лучше\"\n","print(\"Отличная работа!\")"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["448/448 [==============================] - 3s 6ms/step\n","\n","Окончательная точность на тестовых данных: 0.96523\n","Отличная работа!\n"]}]}]}